import{_ as i,r as a,o as c,c as s,b as e,e as l,w as o,d as n}from"./app-VitiyI7N.js";const h={},d=e("h1",{id:"支持向量机",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#支持向量机","aria-hidden":"true"},"#"),n(" 支持向量机")],-1),_=e("h1",{id:"参考资料",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#参考资料","aria-hidden":"true"},"#"),n(" 参考资料")],-1),u=e("ul",null,[e("li",null,"《统计学习方法》李航")],-1),m=e("p",null,"本章的结构和大部分内容均参考此书对应章节。",-1),p=e("hr",null,null,-1),f=e("p",null,"以下待仔细研究：",-1),g={href:"https://blog.csdn.net/v_july_v/article/details/7624837",target:"_blank",rel:"noopener noreferrer"},b=e("p",null,"待看",-1),v={href:"https://www.cnblogs.com/jerrylead/archive/2011/03/13/1982639.html",target:"_blank",rel:"noopener noreferrer"},M=e("p",null,"这份材料从前几节讲的logistic回归出发，引出了SVM，既揭示了模型间的联系，也让人觉得过渡更自然。",-1),k={href:"https://zhuanlan.zhihu.com/p/36332083",target:"_blank",rel:"noopener noreferrer"},x=e("p",null,"111",-1),V={href:"https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&mid=2247484495&idx=1&sn=4f3a6ce21cdd1a048e402ed05c9ead91&chksm=fdb699d8cac110ce53f4fc5e417e107f839059cb76d3cbf640c6f56620f90f8fb4e7f6ee02f9&mpshare=1&scene=1&srcid=0522xo5euTGK36CZeLB03YGi#rd",target:"_blank",rel:"noopener noreferrer"},w=e("p",null,"111",-1),S={href:"https://www.cnblogs.com/jerrylead/archive/2011/03/18/1988415.html",target:"_blank",rel:"noopener noreferrer"},z=e("p",null,"正则化可能会用到",-1),y={href:"https://mp.weixin.qq.com/s?__biz=MjM5MDEzNDAyNQ==&mid=207384849&idx=7&sn=eda3ef452c5b07cf741e8e01e813a516#rd",target:"_blank",rel:"noopener noreferrer"},E=e("p",null,"这属于项目实践部分，以后有时间了再写吧",-1);function N(j,L){const t=a("RouterLink"),r=a("ExternalLinkIcon");return c(),s("div",null,[d,e("ul",null,[e("li",null,[l(t,{to:"/docs/machine-learning/machine-learning/machine-learning.html"},{default:o(()=>[n("返回上层目录")]),_:1})]),e("li",null,[l(t,{to:"/docs/machine-learning/machine-learning/support-vector-machine/linear-separable-svm/linear-separable-svm.html"},{default:o(()=>[n("线性可分支持向量机与硬间隔最大化")]),_:1})]),e("li",null,[l(t,{to:"/docs/machine-learning/machine-learning/support-vector-machine/linear-svm/linear-svm.html"},{default:o(()=>[n("线性支持向量机与软间隔最大化")]),_:1})]),e("li",null,[l(t,{to:"/docs/machine-learning/machine-learning/support-vector-machine/nonlinear-svm-and-kernel-function/nonlinear-svm-and-kernel-function.html"},{default:o(()=>[n("非线性支持向量机与核函数")]),_:1})]),e("li",null,[l(t,{to:"/docs/machine-learning/machine-learning/support-vector-machine/smo/smo.html"},{default:o(()=>[n("序列最小最优化算法SMO")]),_:1})]),e("li",null,[l(t,{to:"/docs/machine-learning/machine-learning/support-vector-machine/svm-summary/svm-README.html"},{default:o(()=>[n("SVM总结")]),_:1})])]),_,u,m,p,f,e("ul",null,[e("li",null,[e("a",g,[n("支持向量机通俗导论（理解SVM的三层境界）"),l(r)])])]),b,e("ul",null,[e("li",null,[e("a",v,[n("支持向量机SVM（一）"),l(r)])])]),M,e("ul",null,[e("li",null,[e("a",k,[n("攀登传统机器学习的珠峰-SVM (上)"),l(r)])])]),x,e("ul",null,[e("li",null,[e("a",V,[n("理解SVM的核函数和参数"),l(r)])])]),w,e("ul",null,[e("li",null,[e("a",S,[n("规则化和不可分情况处理（Regularization and the non-separable case）"),l(r)])])]),z,e("ul",null,[e("li",null,[e("a",y,[n("【分类战车SVM】附录：用Python做SVM模型"),l(r)])])]),E])}const B=i(h,[["render",N],["__file","support-vector-machine.html.vue"]]);export{B as default};
