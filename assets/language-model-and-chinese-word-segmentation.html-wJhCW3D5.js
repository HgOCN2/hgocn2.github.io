import{_ as l,r as a,o as s,c,b as e,e as o,w as i,d as n}from"./app-VitiyI7N.js";const d={},h=e("h1",{id:"语言模型和中文分词",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#语言模型和中文分词","aria-hidden":"true"},"#"),n(" 语言模型和中文分词")],-1),_=e("h1",{id:"参考资料",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#参考资料","aria-hidden":"true"},"#"),n(" 参考资料")],-1),u={href:"http://www.chinahadoop.cn/course/1344",target:"_blank",rel:"noopener noreferrer"},g=e("p",null,"本节是这门课该章节的课程笔记。",-1);function m(p,f){const t=a("RouterLink"),r=a("ExternalLinkIcon");return s(),c("div",null,[h,e("ul",null,[e("li",null,[o(t,{to:"/docs/machine-learning/natural-language-processing/natural-language-processing.html"},{default:i(()=>[n("返回上层目录")]),_:1})])]),_,e("ul",null,[e("li",null,[e("a",u,[n("《自然语言处理算法精讲》第4章：语言模型和中文分词"),o(r)])])]),g])}const k=l(d,[["render",m],["__file","language-model-and-chinese-word-segmentation.html.vue"]]);export{k as default};
