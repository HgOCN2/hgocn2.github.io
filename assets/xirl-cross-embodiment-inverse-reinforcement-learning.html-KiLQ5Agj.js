import{_ as s,r as t,o as a,c as l,b as e,e as r,w as c,d as n}from"./app-VitiyI7N.js";const m={},d=e("h1",{id:"xirl-cross-embodiment-inverse-reinforcement-learning",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#xirl-cross-embodiment-inverse-reinforcement-learning","aria-hidden":"true"},"#"),n(" XIRL: Cross-embodiment Inverse Reinforcement Learning")],-1),_={href:"https://arxiv.org/pdf/2106.03911.pdf",target:"_blank",rel:"noopener noreferrer"},p=e("p",null,"虽然机器人的数据很少，但是人类执行不同任务的视频却很多，当然机器人和人的构造有不同之处，因此让机器人向人类学习的想法引发了「 跨不同实体迁移学习」的问题。",-1),f=e("p",null,"研究人员开发了交叉具身反向强化学习（Cross-Embodiment Inverse Reinforcement Learning），通过观察人类来学习新的任务，并非是试图像人类那样精确地复制任务，而是学习高层次的任务目标，并以奖励函数的形式总结这些知识，示范学习可以让机器人通过观看互联网上随时可用的视频来学习技能。",-1),h={href:"https://mp.weixin.qq.com/s/JRCQP2S3CbLtUaq8MkP4pQ",target:"_blank",rel:"noopener noreferrer"};function u(g,x){const i=t("RouterLink"),o=t("ExternalLinkIcon");return a(),l("div",null,[d,e("ul",null,[e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/imatation-learning/inverse-reinforcement-learning/paper/paper.html"},{default:c(()=>[n("返回上层目录")]),_:1})])]),e("p",null,[n("paper: "),e("a",_,[n("XIRL: Cross-embodiment Inverse Reinforcement Learning"),r(o)])]),p,f,e("p",null,[e("a",h,[n("Google AI年终总结第六弹：没有波士顿动力的谷歌机器人，发展得怎么样了？"),r(o)])])])}const v=s(m,[["render",u],["__file","xirl-cross-embodiment-inverse-reinforcement-learning.html.vue"]]);export{v as default};
