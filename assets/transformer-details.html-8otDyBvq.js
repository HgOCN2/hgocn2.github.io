import{_ as s,r,o as l,c,b as e,e as t,w as i,d as n}from"./app-VitiyI7N.js";const _={},d=e("h1",{id:"transformer的细节问题",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#transformer的细节问题","aria-hidden":"true"},"#"),n(" transformer的细节问题")],-1),f=e("p",null,"===",-1),m={href:"https://zhuanlan.zhihu.com/p/531425888",target:"_blank",rel:"noopener noreferrer"};function h(u,p){const a=r("RouterLink"),o=r("ExternalLinkIcon");return l(),c("div",null,[d,e("ul",null,[e("li",null,[t(a,{to:"/docs/machine-learning/natural-language-processing/self-attention-and-transformer/self-attention-and-transformer.html"},{default:i(()=>[n("返回上层目录")]),_:1})])]),f,e("p",null,[e("a",m,[n("相对位置编码Transformer的一个理论缺陷与对策"),t(o)])])])}const k=s(_,[["render",h],["__file","transformer-details.html.vue"]]);export{k as default};
