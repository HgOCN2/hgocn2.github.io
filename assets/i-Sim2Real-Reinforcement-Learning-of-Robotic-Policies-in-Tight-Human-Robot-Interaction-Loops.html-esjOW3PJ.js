import{_ as a,r as n,o as c,c as l,b as e,e as i,w as s,d as o}from"./app-VitiyI7N.js";const m={},_=e("h1",{id:"i-sim2real-reinforcement-learning-of-robotic-policies-in-tight-human-robot-interaction-loops",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#i-sim2real-reinforcement-learning-of-robotic-policies-in-tight-human-robot-interaction-loops","aria-hidden":"true"},"#"),o(" i-Sim2Real: Reinforcement Learning of Robotic Policies in Tight Human-Robot Interaction Loops")],-1),p={href:"https://arxiv.org/abs/2207.06572",target:"_blank",rel:"noopener noreferrer"},h=e("p",null,"谷歌的研究团队还证明，数据驱动方法通常适用于不同环境中的不同机器人平台，以学习范围广泛的任务，包括移动操作、导航、运动和乒乓球等，也为学习低层次机器人技能指明了一条明确的道路：可扩展的数据收集。",-1),f=e("p",null,"与互联网上丰富的视频和文本数据不同，机器人数据极其稀缺，难以获取，收集和有效使用代表真实世界交互的丰富数据集的方法是数据驱动方法的关键。",-1),u=e("p",null,"仿真是一种快速、安全和易于并行化的选择，但是在仿真中很难复制完整的环境，特别是物理环境和人机交互环境。",-1),d=e("p",null,"在 i-Sim2Real 中，研究人员展示了一种方法，通过从简单的人类行为模型中自举，并在模拟训练和在现实世界中部署之间交替进行，来解决仿真与现实之间的不匹配问题，并学习与人类对手打乒乓球，在每次迭代中，人类行为模型和策略都会得到细化。",-1);function R(b,g){const t=n("RouterLink"),r=n("ExternalLinkIcon");return c(),l("div",null,[_,e("ul",null,[e("li",null,[i(t,{to:"/docs/machine-learning/reinforcement-learning/sim2real/paper/paper.html"},{default:s(()=>[o("返回上层目录")]),_:1})])]),e("p",null,[o("paper: "),e("a",p,[o("i-Sim2Real"),i(r)])]),h,f,u,d])}const x=a(m,[["render",R],["__file","i-Sim2Real-Reinforcement-Learning-of-Robotic-Policies-in-Tight-Human-Robot-Interaction-Loops.html.vue"]]);export{x as default};
