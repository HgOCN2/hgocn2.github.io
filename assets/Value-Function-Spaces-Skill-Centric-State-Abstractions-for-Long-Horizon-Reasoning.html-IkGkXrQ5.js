import{_ as r,r as a,o as s,c as i,b as n,e as o,w as c,d as e}from"./app-VitiyI7N.js";const _={},p=n("h1",{id:"value-function-spaces-skill-centric-state-abstractions-for-long-horizon-reasoning",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#value-function-spaces-skill-centric-state-abstractions-for-long-horizon-reasoning","aria-hidden":"true"},"#"),e(" Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning")],-1),u={href:"https://arxiv.org/abs/2111.03189",target:"_blank",rel:"noopener noreferrer"},d=n("p",null,"当LLM遇上机器人",-1),h=n("p",null,"大型语言模型(LLM)的一个特性是能够将描述和上下文编码成「人和机器都能理解」的格式。",-1),f=n("p",null,"当把LLM应用到机器人技术中时，可以让用户仅通过自然语言指令就能给机器人分配任务；当与视觉模型和机器人学习方法相结合时，LLM 为机器人提供了一种理解用户请求的上下文的方法，并能够对完成请求所采取的行动进行规划。",-1),g=n("p",null,"研究人员选择使用 LLM 来预测完成长期任务的步骤顺序，以及一个表示机器人在给定情况下实际能够完成的技能的affordance 模型。",-1),L=n("p",null,"强化学习模型中的价值函数可以用来建立affordance 模型，即一个机器人在不同状态下可以执行的动作的抽象表示，从而将现实世界中的长期任务，如「整理卧室」与完成任务所需的短期技能，如正确挑选、放置和安排物品等联系起来。",-1),m={href:"https://mp.weixin.qq.com/s/JRCQP2S3CbLtUaq8MkP4pQ",target:"_blank",rel:"noopener noreferrer"};function k(b,S){const l=a("RouterLink"),t=a("ExternalLinkIcon");return s(),i("div",null,[p,n("ul",null,[n("li",null,[o(l,{to:"/docs/machine-learning/artificial-general-intelligence/autopilot/planning/llm-based-planning/llm-based-planning.html"},{default:c(()=>[e("返回上层目录")]),_:1})])]),n("p",null,[e("paper: "),n("a",u,[e("Value Function Spaces"),o(t)])]),d,h,f,g,L,n("p",null,[n("a",m,[e("Google AI年终总结第六弹：没有波士顿动力的谷歌机器人，发展得怎么样了？"),o(t)])])])}const C=r(_,[["render",k],["__file","Value-Function-Spaces-Skill-Centric-State-Abstractions-for-Long-Horizon-Reasoning.html.vue"]]);export{C as default};
