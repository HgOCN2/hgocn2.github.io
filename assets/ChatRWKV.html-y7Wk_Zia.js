import{_ as s,r as l,o as a,c as i,b as e,e as n,w as c,d as t}from"./app-VitiyI7N.js";const h="/assets/discord-rwkv-ksQVg07s.png",u={},_=e("h1",{id:"chatrwkv",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#chatrwkv","aria-hidden":"true"},"#"),t(" ChatRWKV")],-1),p=e("p",null,"ChatRWKV 对标ChatGPT的开源项目",-1),d={href:"https://www.zhihu.com/people/bopengbopeng",target:"_blank",rel:"noopener noreferrer"},g={href:"https://zhuanlan.zhihu.com/p/603840957",target:"_blank",rel:"noopener noreferrer"},k={href:"https://github.com/BlinkDL/RWKV-LM",target:"_blank",rel:"noopener noreferrer"},b={href:"https://discord.com/invite/bDSBUMeFpc",target:"_blank",rel:"noopener noreferrer"},m=e("blockquote",null,[e("p",null,"Discord，聊天软件，是一家游戏聊天应用与社区，Discord从游戏语音、IM工具服务起家，随后转向直播平台，进而开设游戏商店的社区平台，成为游戏玩家在游戏中沟通协作的首选工具。")],-1),f=e("p",null,[e("img",{src:h,alt:"discord-rwkv"})],-1),R=e("p",null,"为实现这一目标，只需四个方面，现均有基础，欢迎大家来建设生态：",-1),V={href:"https://github.com/BlinkDL/RWKV-LM",target:"_blank",rel:"noopener noreferrer"},W=e("li",null,[e("p",null,"**数据。**有国外国内多个团队收集整理数据，包括收集RLHF数据。")],-1),K=e("li",null,[e("p",null,"**模型。**ChatRWKV采用我设计的RWKV架构（魔改RNN，是迄今唯一看齐transformer性能的纯RNN，梯度可以无限走，也能并行化，拥有RNN和transformer的所有优点），效率高于GPT（运行快，省显存，适合在端侧离线运行），不仅适用于语言模型，也有潜力成为未来AI模型的基础。现已scale到14B验证，等大语料发布后再逐步scale到100B+【补充为何RWKV这样强：RWKV几乎不碰信息channel，它们就只是exponential decay而已，没有更多的非线性。其它RNN在上面的非线性太多，容易破坏信息】。")],-1),N=e("li",null,[e("p",null,"**开发者和生态。**ChatRWKV项目发布3个星期在Github已有1.8k stars，有多位开发者建设，且OpenAI和Huggingface等等都在密切关注ChatRWKV（他们给我发过邮件）。")],-1),w=e("p",null,"RNN-based 没有attention之类机制的模型是怎么获得long memory的能力的啊？",-1),B={href:"http://link.zhihu.com/?target=https%3A//arxiv.org/abs/2006.16236",target:"_blank",rel:"noopener noreferrer"},C={href:"http://link.zhihu.com/?target=https%3A//openreview.net/forum%3Fid%3DIxmWsm4xrua",target:"_blank",rel:"noopener noreferrer"},L=e("p",null,"slow decaying units",-1),x=e("p",null,"模型大小现在能压到多少？ 能到5GB以内吗",-1),v=e("blockquote",null,[e("p",null,"已经有人做了简单的8bit量化版，其实认真做到3bit或4bit是没问题的。")],-1),D=e("p",null,"请问pytorch版本不同是不是效果也不一样？还是说模型影响更大些。感觉3B模型效果很差，7B模型勉强能用，14B没敢跑……",-1),M=e("blockquote",null,[e("p",null,"肯定模型影响大啊，大力出奇迹")],-1),z=e("p",null,"建议套皮个webui，这样子普通人也能玩。",-1),G=e("blockquote",null,[e("p",null,"套个webui，很多玩sd的小白也会跟风跑过来玩了。 论开源分布式训练的ai，我还是佩服当年里拉zero的。"),e("p",null,"欢迎大家来做傻瓜包，其实 chatRWKV 已经很容易用了，直接用最新torch就能跑。"),e("p",null,"确实，套皮webui是很好的选择")],-1);function q(y,A){const r=l("RouterLink"),o=l("ExternalLinkIcon");return a(),i("div",null,[_,e("ul",null,[e("li",null,[n(r,{to:"/docs/machine-learning/natural-language-processing/large-language-model/industry-application/blinkdl/blinkdl.html"},{default:c(()=>[t("返回上层目录")]),_:1})])]),p,e("p",null,[t("创始人知乎主页："),e("a",d,[t("PENG Bo"),n(o)])]),e("p",null,[e("a",g,[t("知乎：参与 ChatRWKV 项目，做开源 ChatGPT（可以在每个人电脑和手机直接运行的）"),n(o)])]),e("p",null,[t("ChatRWKV训练代码："),e("a",k,[t("https://github.com/BlinkDL/RWKV-LM"),n(o)])]),e("p",null,[t("ChatRWKV Discord交流: "),e("a",b,[t("RWKV Language Model"),n(o)])]),m,f,R,e("ol",null,[e("li",null,[e("p",null,[t("**算力。**我平时用上百张A100训练，有需要可以用上千张。其实如果有经验，一个人就可以炼100B模型。训练代码："),e("a",V,[t("GitHub - BlinkDL/RWKV-LM"),n(o)])])]),W,K,N]),w,e("blockquote",null,[e("p",null,[t("这个形式就是"),e("a",B,[t("Transformers are RNNs"),n(o)]),t("的形式，只不过把Q换成了positional invariant的time weighting。 最近很多work都显示Attention里的Q其实没啥用，换成一个跟着相对位置exponential decay的term就行了, e.g. "),e("a",C,[t("Toeplitz Neural Network for Sequence Modeling"),n(o)])]),L]),x,v,D,M,z,G])}const T=s(u,[["render",q],["__file","ChatRWKV.html.vue"]]);export{T as default};
