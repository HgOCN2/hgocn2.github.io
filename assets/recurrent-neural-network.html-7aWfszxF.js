import{_ as r,r as e,o as i,c as p,b as s,e as t,w as c,d as a,a as l}from"./app-VitiyI7N.js";const o="/assets/slot-filling-YZxRxQXA.jpg",h="/assets/book-tiket-OFLQqs5i.jpg",u="/assets/rnn-rHyOtc3n.jpg",g="/assets/rnn-example1-Z9paO6He.jpg",d="/assets/rnn-example2-0uW0GJqH.jpg",x="/assets/rnn-example3-j2LgHH6c.jpg",w="/assets/rnn-example4-ECBh1A9o.jpg",y="/assets/rnn-example5-v-44ELG7.jpg",_="/assets/rnn-structure4-oNf9I6GL.jpg",k="/assets/rnn-structure1-otggMVAx.jpg",b="/assets/rnn-structure2-u9903oEu.jpg",N="/assets/rnn-structure3-yNoZRw4q.jpg",M="/assets/rnn-vanishing-gradient-MtVMjEXq.png",v={},f=s("h1",{id:"rnn循环神经网络",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#rnn循环神经网络","aria-hidden":"true"},"#"),a(" RNN循环神经网络")],-1),R=l('<li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81RNN">为什么需要RNN</a></li><li><a href="*RNN%E5%8E%9F%E7%90%86">RNN原理</a><ul><li><a href="#%E7%9B%B4%E8%A7%82%E5%9B%BE%E8%A7%A3">直观图解</a></li><li><a href="#%E5%85%AC%E5%BC%8F">公式</a></li></ul></li><li><a href="#RNN%E7%9A%84%E4%B8%8D%E5%90%8C%E6%9E%B6%E6%9E%84">RNN的不同架构</a><ul><li><a href="#%E5%A4%9A%E5%B1%82Deep%E7%9A%84RNN">多层Deep的RNN</a></li><li><a href="#Elman%E5%92%8CJordan%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84">Elman和Jordan网络架构</a></li><li><a href="#%E5%8F%8C%E5%90%91RNN">双向RNN</a></li></ul></li>',3),L=l('<h1 id="为什么需要rnn" tabindex="-1"><a class="header-anchor" href="#为什么需要rnn" aria-hidden="true">#</a> 为什么需要RNN</h1><p>以订票系统的填空（slot filling）为例，比如一个智慧订票系统，往往需要slot filling技术。</p><p>假设订票系统需要根据人说的话得到两个slot：<code>目的地</code>和<code>到达时间</code>。</p><p><img src="'+o+`" alt="slot-filling"></p><p>这个问题我们首先想到可以用全连接网络（FNN：FeedForword Neural Network）来解决。</p><p>这个全连接网络的输入是一个词汇，比如把台北变为一个Embedding（OneHot、N-gram、Word2vec）输入到神经网络里。然后希望输出是一个概率，即属于所有slot的几率。</p><p>但是只有这样是不够的，全连接网络不能解决这个问题。为什么呢？</p><p>如果有两个输入：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>arrive Taipei on November 2nd
leave Taipei on November 2nd
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>但对于全连接神经网络来说，输入一样，输出也会一样。输入<code>Taipei</code>，要么输出是<code>目的地</code>的几率最高，要么是<code>出发地</code>的几率最高，没有办法有时候让<code>目的地</code>的几率最高，有时候让<code>出发地</code>的几率最高，那怎么办呢？</p><p><strong>这个时候，我们就希望神经网络是有记忆力的</strong>。</p><p><img src="`+h+'" alt="book-tiket"></p><p>如果神经网络是有记忆力的，它会记得在看到红色<code>Taipei</code>这个词之前，就已经看过<code>arrive</code>这个词汇；它会记得在看到绿色<code>Taipei</code>这个词之前，就已经看过<code>leave</code>这个词汇。它会根据这段话的上下文，产生不同的输出。</p><p><strong>如果神经网络是有记忆力的，这样就可以解决输入同样的词汇，但是输出必须不同这个问题</strong>。那么这种有记忆力的神经网络，就叫做Recurrnt Neural Network(RNN)。</p><h1 id="rnn原理" tabindex="-1"><a class="header-anchor" href="#rnn原理" aria-hidden="true">#</a> RNN原理</h1><h2 id="直观图解" tabindex="-1"><a class="header-anchor" href="#直观图解" aria-hidden="true">#</a> 直观图解</h2>',16),E=s("p",null,[a("每次前向神经网络里的隐藏层的神经元产生输出（下图中的"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"a"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"a_1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("和"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"a"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"},"a_2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"a"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("）后，都会被存到memory中去，然后当下一个input输入后，隐藏层的输入不仅仅考虑"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"x_1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("和"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"},"x_2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("，还会考虑上一次的隐藏层输出存在memory中的值。")],-1),z=l('<p><img src="'+u+'" alt="rnn.jpg"></p><p>那具体过程是怎样的呢？用一个简单的例子来说明会比较清楚。</p><p>假设如下图所示的所有权值都是1，所有的神经元都没有bias，假设所有的激活函数都是线性的，假设input是sequence，具体值如下图中所示，假设memory的初始值是0。</p><p><img src="'+g+'" alt="rnn-example1.jpg"></p><p>然后如下图所示<strong>隐藏层的值2被写到memory中</strong>，接下来再输入第二个单词的embedding，那么<strong>隐藏层的输入有四个</strong>，加权的结果是6，输出的结果也是6。</p><p><img src="'+d+'" alt="rnn-example2"></p><p>由上图可以看出，输入是一样的，但是输出是可能不一样的，因为存在memory中的值是不一样的。</p><p>接下来，如下图所示上图中隐藏层的输出6就会被存到memory中去，memory中的值就由2变为6。隐藏层的输入有四个（6+6+2+2=16），所以隐层的输出就是16。</p><p><img src="'+x+'" alt="rnn-example3"></p><p>所以因为memory的存在，<strong>任意调换sequence的顺序，那么输出就会不一样</strong>。比如把sequence的最后一个单词挪到最前面去，则输出是会完全不一样的。所以，<strong>RNN会考虑输入的seqence的顺序</strong>。</p><p><strong>example</strong>：</p><p>现在RNN的原理就讲完了，下面还是用前面的订票系统来距离说明。</p><p><img src="'+w+'" alt="rnn-example4"></p><p>上面并不是三个网络，而是同一个神经网络，是同一个网络在三个不同的时间点被使用了三次。</p><p>所以，有了memory以后，我们希望输入同一个词汇，输出不同的概率这个问题，就有可能解决。</p>',15),B=s("p",null,[a("如下图所示，同样是输入"),s("code",null,"Taipei"),a("，但是因为红色"),s("code",null,"Taipei"),a("前面接"),s("code",null,"leave"),a("，绿色"),s("code",null,"Taipei"),a("前面接"),s("code",null,"arrive"),a("，因为"),s("code",null,"leave"),a("和"),s("code",null,"arrive"),a("它们的embedding不一样，所以隐层的输出也会不同，存在memory里面的值也会不同。所以虽然现在两个"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"x"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"},"x^2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])]),a("是一模一样的，但是因为存在memory里面的值不同，所以隐层的输出就会不一样，所以最后的输出也就会不一样。")],-1),T=s("p",null,[s("img",{src:y,alt:"rnn-example5"})],-1),j=s("h2",{id:"公式",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#公式","aria-hidden":"true"},"#"),a(" 公式")],-1),q=s("p",null,[s("img",{src:_,alt:"rnn-structure4"})],-1),V=s("p",null,[a("这是一个标准的RNN结构图，图中每个箭头代表做一次变换，也就是说箭头连接带有权值。左侧是折叠起来的样子，右侧是展开的样子，左侧中"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"h")]),s("annotation",{encoding:"application/x-tex"},"h")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"h")])])]),a("旁边的箭头代表此结构中的“循环“体现在隐层。")],-1),A=s("p",null,[s("strong",null,"前向传播算法：")],-1),U=s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"x")]),s("annotation",{encoding:"application/x-tex"},"x")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"x")])])]),a("是输入，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"h")]),s("annotation",{encoding:"application/x-tex"},"h")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"h")])])]),a("是隐层单元，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"o")]),s("annotation",{encoding:"application/x-tex"},"o")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"o")])])]),a("为输出，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L")]),s("annotation",{encoding:"application/x-tex"},"L")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"L")])])]),a("为损失函数，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y")]),s("annotation",{encoding:"application/x-tex"},"y")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")])])]),a("为训练集的标签。这些元素右上角带的t代表"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"t")]),s("annotation",{encoding:"application/x-tex"},"t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6151em"}}),s("span",{class:"mord mathnormal"},"t")])])]),a("时刻的状态，其中需要注意的是，因此单元"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"h")]),s("annotation",{encoding:"application/x-tex"},"h")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"h")])])]),a("在"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"t")]),s("annotation",{encoding:"application/x-tex"},"t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6151em"}}),s("span",{class:"mord mathnormal"},"t")])])]),a("时刻的表现不仅由此刻的输入决定，还受"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"t")]),s("annotation",{encoding:"application/x-tex"},"t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6151em"}}),s("span",{class:"mord mathnormal"},"t")])])]),a("时刻之前时刻的影响。"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"V")]),s("annotation",{encoding:"application/x-tex"},"V")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V")])])]),a("、"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"W")]),s("annotation",{encoding:"application/x-tex"},"W")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W")])])]),a("、"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"U")]),s("annotation",{encoding:"application/x-tex"},"U")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U")])])]),a("是权值，同一类型的权连接权值相同。")],-1),S=s("p",null,[a("前向传播算法其实非常简单，对于"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"t")]),s("annotation",{encoding:"application/x-tex"},"t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6151em"}}),s("span",{class:"mord mathnormal"},"t")])])]),a("时刻：")],-1),P=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"h"),s("mo",{stretchy:"false"},"("),s("mi",null,"t"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"ϕ"),s("mo",{stretchy:"false"},"("),s("mi",null,"U"),s("mo",null,"⋅"),s("mi",null,"x"),s("mo",{stretchy:"false"},"("),s("mi",null,"t"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"W"),s("mo",null,"⋅"),s("mi",null,"h"),s("mo",{stretchy:"false"},"("),s("mi",null,"t"),s("mo",null,"−"),s("mn",null,"1"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"b"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," h(t)=ϕ(U\\cdot x(t)+W\\cdot h(t−1)+b) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"h"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"ϕ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"U"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"h"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},")")])])])])],-1),C=s("p",null,[a("其中"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"ϕ"),s("mo",{stretchy:"false"},"("),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"\\phi()")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"ϕ"),s("span",{class:"mopen"},"("),s("span",{class:"mclose"},")")])])]),a("为激活函数，一般来说会选择"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"t"),s("mi",null,"a"),s("mi",null,"n"),s("mi",null,"h")]),s("annotation",{encoding:"application/x-tex"},"tanh")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"anh")])])]),a("函数，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"b")]),s("annotation",{encoding:"application/x-tex"},"b")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"b")])])]),a("为偏置。")],-1),W=s("p",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"t")]),s("annotation",{encoding:"application/x-tex"},"t")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6151em"}}),s("span",{class:"mord mathnormal"},"t")])])]),a("时刻的"),s("strong",null,"输出"),a("就更为简单：")],-1),J=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"o"),s("mo",{stretchy:"false"},"("),s("mi",null,"t"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"V"),s("mo",null,"⋅"),s("mi",null,"h"),s("mo",{stretchy:"false"},"("),s("mi",null,"t"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"c")]),s("annotation",{encoding:"application/x-tex"}," o(t)=V\\cdot h(t)+c ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"⋅"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"h"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"c")])])])])],-1),F=s("p",null,"最终模型的预测输出为：",-1),D=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mo",{stretchy:"false"},"("),s("mi",null,"t"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"σ"),s("mo",{stretchy:"false"},"("),s("mi",null,"o"),s("mo",{stretchy:"false"},"("),s("mi",null,"t"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," \\hat{y}(t)=\\sigma(o(t)) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mclose"},"))")])])])])],-1),G=s("p",null,[a("其中"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"σ")]),s("annotation",{encoding:"application/x-tex"},"\\sigma")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ")])])]),a("为激活函数，通常RNN用于分类，故这里一般用softmax函数。")],-1),H=l('<p><strong>损失函数</strong></p><p>对于分类问题，采用交叉熵。</p><p><strong>后向传播算法：</strong></p><p>BPTT（back-propagation through time）算法是常用的训练RNN的方法，其实本质还是BP算法，只不过RNN处理时间序列数据，所以要基于时间反向传播，故叫随时间反向传播。BPTT的中心思想和BP算法相同，沿着需要优化的参数的负梯度方向不断寻找更优的点直至收敛。综上所述，BPTT算法本质还是BP算法，BP算法本质还是梯度下降法，那么求各个参数的梯度便成了此算法的核心。</p><p>需要寻优的参数有三个，分别是U、V、W。与BP算法不同的是，其中W和U两个参数的寻优过程需要追溯之前的历史数据，参数V相对简单只需关注目前。</p><h1 id="rnn的不同架构" tabindex="-1"><a class="header-anchor" href="#rnn的不同架构" aria-hidden="true">#</a> RNN的不同架构</h1><h2 id="多层deep的rnn" tabindex="-1"><a class="header-anchor" href="#多层deep的rnn" aria-hidden="true">#</a> 多层Deep的RNN</h2><p>RNN当然也可以有很多层，如下图所示</p><p><img src="'+k+'" alt="rnn-structure"></p><h2 id="elman和jordan网络架构" tabindex="-1"><a class="header-anchor" href="#elman和jordan网络架构" aria-hidden="true">#</a> Elman和Jordan网络架构</h2>',10),O=s("p",null,[a("前面我们讲的都是Elman网络架构，Jordan网络往memory中存的是output的值。Jordan网络可以得到比较好的性能，因为Elman网络的隐藏层是没有target的，比较难控制它学到了什么信息，但是Jordan网络的输出"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y")]),s("annotation",{encoding:"application/x-tex"},"y")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")])])]),a("是有target的，可以对放在memory中的是什么东西比较清楚的。")],-1),I=s("p",null,[s("img",{src:b,alt:"rnn-structure2"})],-1),Q=s("h2",{id:"双向rnn",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#双向rnn","aria-hidden":"true"},"#"),a(" 双向RNN")],-1),Z=s("p",null,"RNN的读取方向不仅可以是按照句子的顺序，也可以是反过来的。",-1),X=s("p",null,"可以同时train一个正向的RNN和逆向的RNN，然后把两个RNN的隐藏层都拿出来接给一个输出层，得到最后的输出y。",-1),Y=s("p",null,[s("img",{src:N,alt:"rnn-structure3"})],-1),K=s("p",null,[a("用双向RNN的好处，就是网络产生输出的时候，看的范围比较广。如果只有正向的RNN，在产生"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"y"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"},"y^{t+1}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0085em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])])])])])])])])]),a("的时候，网络只看过"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"x"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"x^1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])])])])]),a("一直到"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"x"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"},"x^{t+1}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])])])])])])])])]),a("，但是如果是双向的RNN，在产生"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"y"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"},"y^{t+1}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0085em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])])])])])])])])]),a("的时候，网络不只是看过"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"x"),s("mn",null,"1")])]),s("annotation",{encoding:"application/x-tex"},"x^1")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])])])])])])])])]),a("一直到"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"x"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"},"x^{t+1}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])])])])])])])])]),a("，也看了从句尾一直到"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"x"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"},"x^{t+1}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8141em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])])])])])])])])]),a("。就是说，"),s("strong",null,"网络是看了整个sequence后，才决定输出是什么"),a("，会比只看句子的一半得到更好的性能。")],-1),$=l('<h1 id="rnn的梯度消失问题" tabindex="-1"><a class="header-anchor" href="#rnn的梯度消失问题" aria-hidden="true">#</a> RNN的梯度消失问题</h1><p>RNN的缺陷是梯度消失问题，即便是LSTM也只能缓解该问题。</p><p><img src="'+M+'" alt="rnn-vanishing-gradient"></p><h1 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料" aria-hidden="true">#</a> 参考资料</h1>',4),ss={href:"http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/RNN1.mp4",target:"_blank",rel:"noopener noreferrer"},as={href:"https://www.bilibili.com/video/av73798762?p=43",target:"_blank",rel:"noopener noreferrer"},ts=s("p",null,"本文参考了该视频。两个视频都一样。",-1),ns={href:"https://www.superdatascience.com/blogs/recurrent-neural-networks-rnn-the-vanishing-gradient-problem",target:"_blank",rel:"noopener noreferrer"},ls={href:"http://proceedings.mlr.press/v28/pascanu13.pdf?source=post_page---------------------------",target:"_blank",rel:"noopener noreferrer"},es=s("p",null,'"RNN的梯度消失问题"参考该博客，paper没看，但是觉得有用。',-1),ms=s("p",null,"===",-1),rs={href:"https://zhuanlan.zhihu.com/p/28054589",target:"_blank",rel:"noopener noreferrer"},is={href:"https://blog.csdn.net/jerr__y/article/details/53749693",target:"_blank",rel:"noopener noreferrer"},ps=s("p",null,"RNN基础 对于RNN，我看到讲得最通俗易懂的应该是Andrej发的博客： The Unreasonable Effectiveness of Recurrent Neural Networks",-1),cs=s("p",null,"这里有它的中文翻译版本： 递归神经网络不可思议的有效性",-1),os=s("p",null,"如果想了解 LSTM 的原理，可以参考这篇文章：（译）理解 LSTM 网络 （Understanding LSTM Networks by colah）。 下面的连接中对RNN还有BPTT（RNN的反向传播算法），LSTM和GRU的原理和实现讲解得也是非常棒： http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/",-1),hs={href:"https://distill.pub/2019/memorization-in-rnns/",target:"_blank",rel:"noopener noreferrer"},us={href:"https://www.zhihu.com/question/314002073",target:"_blank",rel:"noopener noreferrer"},gs={href:"https://zhuanlan.zhihu.com/p/35878575",target:"_blank",rel:"noopener noreferrer"},ds={href:"https://zhuanlan.zhihu.com/p/37428697",target:"_blank",rel:"noopener noreferrer"},xs={href:"https://yq.aliyun.com/articles/169880?spm=a2c4e.11153940.blogcont86580.22.152919797EqPuO",target:"_blank",rel:"noopener noreferrer"},ws={href:"https://mp.weixin.qq.com/s/3Rpq1EvYi-_9wvJ5fUB5dQ",target:"_blank",rel:"noopener noreferrer"},ys={href:"https://cuijiahua.com/blog/2018/12/dl-11.html",target:"_blank",rel:"noopener noreferrer"},_s={href:"https://www.superdatascience.com/blogs/the-ultimate-guide-to-recurrent-neural-networks-rnn",target:"_blank",rel:"noopener noreferrer"};function ks(bs,Ns){const m=e("RouterLink"),n=e("ExternalLinkIcon");return i(),p("div",null,[f,s("ul",null,[s("li",null,[t(m,{to:"/docs/machine-learning/deep-learning/recurrent-neural-network/recurrent-neural-network.html"},{default:c(()=>[a("返回上层目录")]),_:1})]),R]),L,E,z,B,T,j,q,V,A,U,S,P,C,W,J,F,D,G,H,O,I,Q,Z,X,Y,K,$,s("ul",null,[s("li",null,[s("a",ss,[a("李宏毅教授讲解 RNN LSTM的视频"),t(n)])]),s("li",null,[s("a",as,[a("B站李宏毅深度学习RNN2019"),t(n)])])]),ts,s("ul",null,[s("li",null,[s("a",ns,[a("Recurrent Neural Networks (RNN) - The Vanishing Gradient Problem"),t(n)])]),s("li",null,[s("a",ls,[a("paper: On the difficulty of training recurrent neural networks"),t(n)])])]),es,ms,s("p",null,[s("a",rs,[a("完全图解RNN、RNN变体、Seq2Seq、Attention机制"),t(n)])]),s("p",null,[s("a",is,[a("seq2seq学习笔记"),t(n)])]),ps,cs,os,s("p",null,[s("a",hs,[a("Visualizing memorization in RNNs"),t(n)])]),s("p",null,[s("a",us,[a("谁能用比较通俗有趣的语言解释RNN和LSTM？"),t(n)])]),s("p",null,[s("a",gs,[a("一文读懂LSTM和循环神经网络"),t(n)])]),s("p",null,[s("a",ds,[a("深度学习循环神经网络详解"),t(n)])]),s("p",null,[s("a",xs,[a("【深度学习之美】循环递归RNN，序列建模套路深（入门系列之十三）"),t(n)])]),s("p",null,[s("a",ws,[a("【Deep Learning】通俗大白话详述RNN理论和LSTM理论"),t(n)])]),s("p",null,[s("a",ys,[a("深度学习实战教程(五)：循环神经网络"),t(n)])]),s("p",null,[s("a",_s,[a("The Ultimate Guide to Recurrent Neural Networks (RNN)"),t(n)])])])}const vs=r(v,[["render",ks],["__file","recurrent-neural-network.html.vue"]]);export{vs as default};
