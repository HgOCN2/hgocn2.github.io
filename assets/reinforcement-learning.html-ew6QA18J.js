import{_ as a,r as l,o as c,c as m,b as e,e as r,w as t,d as n}from"./app-VitiyI7N.js";const d={},f=e("h1",{id:"强化学习",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#强化学习","aria-hidden":"true"},"#"),n(" 强化学习")],-1),s=e("p",null,"===",-1),g=e("p",null,"各种强化学习论文及其代码",-1),h={href:"https://github.com/keiohta/tf2rl",target:"_blank",rel:"noopener noreferrer"};function u(_,p){const i=l("RouterLink"),o=l("ExternalLinkIcon");return c(),m("div",null,[f,e("ul",null,[e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning.html"},{default:t(()=>[n("返回上层目录")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/reinforcement-learning-introduction/reinforcement-learning-introduction.html"},{default:t(()=>[n("强化学习概论")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/state-reward-action/state-reward-action.html"},{default:t(()=>[n("状态、奖励、动作")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/multi-armed-bandit-and-solutions/multi-armed-bandit-and-solutions.html"},{default:t(()=>[n("多臂赌博机及其解法")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/markov-decision-processes/markov-decision-processes.html"},{default:t(()=>[n("马尔科夫决策过程")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/dynamic-programming/dynamic-programming.html"},{default:t(()=>[n("动态规划")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/model-free-methods-1-monte-carlo/model-free-methods-1-monte-carlo.html"},{default:t(()=>[n("无模型方法一：蒙特卡洛")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/model-free-methods-2-time-difference/model-free-methods-2-time-difference.html"},{default:t(()=>[n("无模型方法二：时间差分")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/model-free-methods-3-multi-step-bootstrap/model-free-methods-3-multi-step-bootstrap.html"},{default:t(()=>[n("无模型方法三：多步自举")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/function-approximation-and-deep-network/function-approximation-and-deep-network.html"},{default:t(()=>[n("函数近似和深度网络")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/policy-gradient-algorithm/policy-gradient-algorithm.html"},{default:t(()=>[n("策略梯度算法")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/deep-reinforcement-learning/deep-reinforcement-learning.html"},{default:t(()=>[n("深度强化学习")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/model-based-reinforcement-learning/model-based-reinforcement-learning.html"},{default:t(()=>[n("基于模型的强化学习")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/reinforcement-learning-prospect/reinforcement-learning-prospect.html"},{default:t(()=>[n("强化学习前景")]),_:1})]),e("li",null,[r(i,{to:"/docs/machine-learning/reinforcement-learning/reinforcement-learning/paper/paper.html"},{default:t(()=>[n("强化学习论文")]),_:1})])]),s,g,e("p",null,[e("a",h,[n("keiohta/tf2rl"),r(o)])])])}const b=a(d,[["render",u],["__file","reinforcement-learning.html.vue"]]);export{b as default};
