<template><div><h1 id="任务清单" tabindex="-1"><a class="header-anchor" href="#任务清单" aria-hidden="true">#</a> 任务清单</h1>
<ul>
<li><RouterLink to="/docs/machine-learning/">返回上层目录</RouterLink></li>
</ul>
<h1 id="agi" tabindex="-1"><a class="header-anchor" href="#agi" aria-hidden="true">#</a> AGI</h1>
<ul>
<li><a href="https://arxiv.org/abs/2010.06002" target="_blank" rel="noopener noreferrer">Thinking Fast And Slow in AI<ExternalLinkIcon/></a></li>
</ul>
<p>本文从人类能力中汲取灵感，提出了走向更通用和更值得信赖的人工智能（AGI）和人工智能研究社区的 10 个问题。</p>
<h1 id="自动驾驶" tabindex="-1"><a class="header-anchor" href="#自动驾驶" aria-hidden="true">#</a> 自动驾驶</h1>
<p><strong>Tesla's Autopilot Explained</strong></p>
<p>https://www.louisbouchard.ai/tesla-autopilot-explained-tesla-ai-day/</p>
<p>本文中，特斯拉人工智能总监安德烈·卡帕西等人展示了特斯拉的自动驾驶系统是如何通过他们的八个摄像头采集图像，实现道路上导航。</p>
<h1 id="计算机视觉" tabindex="-1"><a class="header-anchor" href="#计算机视觉" aria-hidden="true">#</a> 计算机视觉</h1>
<h2 id="视频" tabindex="-1"><a class="header-anchor" href="#视频" aria-hidden="true">#</a> 视频</h2>
<p><strong>Time Lens: Event-based Video Frame Interpolation</strong></p>
<p>http://rpg.ifi.uzh.ch/docs/CVPR21_Gehrig.pdf</p>
<p>TimeLens 模型可以理解视频帧之间的粒子运动，以人眼无法捕捉的速度重建视频。事实上，本文中的模型效果达到了目前智能手机都无法达到的效果。</p>
<h1 id="深度学习" tabindex="-1"><a class="header-anchor" href="#深度学习" aria-hidden="true">#</a> 深度学习</h1>
<h2 id="生成对抗" tabindex="-1"><a class="header-anchor" href="#生成对抗" aria-hidden="true">#</a> 生成对抗</h2>
<p><strong>Generative Adversarial Transformers</strong></p>
<p>https://arxiv.org/pdf/2103.01209.pdf</p>
<p>本文利用了强大的 StyleGAN2 架构中Transformer的注意力机制，使其更加强大！</p>
<p><strong>Sketch Your Own GAN</strong></p>
<p>https://arxiv.org/abs/2108.02774</p>
<p>通过按照草图生成图像，让每个人都可以更轻松地进行 GAN 训练！事实上，借助这种新方法，您可以根据最简单的知识类型来控制 GAN 的输出：手绘草图。</p>
<h2 id="照片处理" tabindex="-1"><a class="header-anchor" href="#照片处理" aria-hidden="true">#</a> 照片处理</h2>
<p><strong>Total Relighting: Learning to Relight Portraits for Background Replacement</strong></p>
<p>https://augmentedperception.github.io/total_relighting/total_relighting_paper.pdf</p>
<p>你有没有想过改变图片的背景，但让它看起来很逼真？这并不简单。你不能只是在家里拍一张自己的照片，然后换成海滩背景。图片看起来会很假，任何人都会马上看出「这是PS的」。本文提出的方法可能会完美解决这个问题。</p>
<h1 id="推荐系统" tabindex="-1"><a class="header-anchor" href="#推荐系统" aria-hidden="true">#</a> 推荐系统</h1>
<p><a href="https://zhuanlan.zhihu.com/p/67795161" target="_blank" rel="noopener noreferrer">FFM及DeepFFM模型在推荐系统的探索<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/67218758" target="_blank" rel="noopener noreferrer">Embedding在深度推荐系统中的3大应用方向<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/52930683" target="_blank" rel="noopener noreferrer">乱弹机器学习评估指标AUC<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/77494496" target="_blank" rel="noopener noreferrer">以youtube的RL论文学习如何在推荐场景应用RL<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/83103245" target="_blank" rel="noopener noreferrer">经典！工业界深度推荐系统与CTR预估必读的论文汇总<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/85950252" target="_blank" rel="noopener noreferrer">Google图嵌入工业界最新大招，高效解决训练大规模深度图卷积神经网络问题<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/53361519" target="_blank" rel="noopener noreferrer">详解 Wide &amp; Deep 结构背后的动机<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/55234968" target="_blank" rel="noopener noreferrer">揭秘 Deep &amp; Cross : 如何自动构造高阶交叉特征<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/57987311" target="_blank" rel="noopener noreferrer">回顾Facebook经典CTR预估模型<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/57481330" target="_blank" rel="noopener noreferrer">阿里CVR预估模型之ESMM<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/74242097" target="_blank" rel="noopener noreferrer">GraphSAGE：我寻思GCN也没我牛逼<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/55135954" target="_blank" rel="noopener noreferrer">LR+FTRL算法原理以及工程化实现<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/92839767" target="_blank" rel="noopener noreferrer">结合YouTube Top-K 论文谈谈强化学习落地<ExternalLinkIcon/></a></p>
<p><a href="https://www.zhihu.com/question/315872728" target="_blank" rel="noopener noreferrer">图神经网络（GCN、GraphSage、GAT）等在公司实际推荐系统中有应用么？<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/77694065" target="_blank" rel="noopener noreferrer">强化学习在推荐算法的应用论文整理（二）<ExternalLinkIcon/></a></p>
<p><a href="http://proceedings.mlr.press/v97/chen19f/chen19f.pdf" target="_blank" rel="noopener noreferrer">Generative Adversarial User Model for Reinforcement Learning Based Recommendation System<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/97123417" target="_blank" rel="noopener noreferrer">BERT4REC：使用Bert进行推荐<ExternalLinkIcon/></a></p>
<p><a href="https://blog.csdn.net/qq_40210472/article/details/89819021" target="_blank" rel="noopener noreferrer">Next Item Recommendation with Self-Attention<ExternalLinkIcon/></a></p>
<p><a href="http://www.rabin.tech/2019/01/11/%E3%80%8ANext-Item-Recommendation-with-Self-Attention%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" target="_blank" rel="noopener noreferrer">《Next Item Recommendation with Self-Attention》阅读笔记<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/109835504" target="_blank" rel="noopener noreferrer">多任务学习在推荐算法中的应用<ExternalLinkIcon/></a></p>
<p>阿里杭州发的deep session interest nerwork DSIN 使用transformer还是有一些道理的，bert4rec相对就……</p>
<p><a href="https://zhuanlan.zhihu.com/p/97123417" target="_blank" rel="noopener noreferrer">BERT4REC：使用Bert进行推荐<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/60185134" target="_blank" rel="noopener noreferrer">AutoInt：基于Multi-Head Self-Attention构造高阶特征<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/109933924" target="_blank" rel="noopener noreferrer">CTR预估模型：DeepFM/Deep&amp;Cross/xDeepFM/AutoInt代码实战与讲解<ExternalLinkIcon/></a></p>
<p><a href="https://www.zhihu.com/question/363531892/answer/1062392197" target="_blank" rel="noopener noreferrer">CTR预估模型有怎样的发展规律？<ExternalLinkIcon/></a>重点</p>
<p><a href="https://www.csie.ntu.edu.tw/~cjlin/papers/liblinear.pdf" target="_blank" rel="noopener noreferrer">LIBLINEAR: A Library for Large Linear Classification<ExternalLinkIcon/></a>，这是机器学习打基础最好的资料</p>
<p><a href="https://zhuanlan.zhihu.com/p/54822778" target="_blank" rel="noopener noreferrer">镶嵌在互联网技术上的明珠：漫谈深度学习时代点击率预估技术进展<ExternalLinkIcon/></a> 对整体的把握非常有帮助！</p>
<p>论文题目：CATN:  Cross-Domain Recommendation for Cold-Start Users via Aspect Transfer Network（一篇用户跨域冷启动的论文，主要涉及用户相关领域的偏好迁移）
论文地址：<a href="https://arxiv.org/abs/2005.10549" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2005.10549<ExternalLinkIcon/></a></p>
<p>注：可以用于不同机型上的初始化冷启动</p>
<p>今晚7点9号会议室，我来为大家分享一篇有关知识蒸馏的文章：Privileged Features Distillation at Taobao Recommendations
提前将网址和PPT发出来，有兴趣的同学可以先看看哈<a href="https://arxiv.org/abs/1907.05171" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/1907.05171<ExternalLinkIcon/></a></p>
<p>这篇文章应该是《Sampling-Bias-Corrected
Neural Modeling for Large Corpus Item Recommendations》
的后续作品，就是之前用in-batch-softmax做双塔的文章，主要应该是改进了之前in-batch形式下负样本的一些缺陷，大家也可以看看:</p>
<p>各位有没有学弟学妹现在还在学校，而且学校有acm dl权限的，求帮下篇文章
<a href="https://dl.acm.org/doi/10.1145/3366424.3386195" target="_blank" rel="noopener noreferrer">https://dl.acm.org/doi/10.1145/3366424.3386195<ExternalLinkIcon/></a>
Mixed Negative Sampling for Learning Two-tower Neural Networks in Recommendations</p>
<p>Controlling Fairness and Bias in Dynamic Learning-to-Rank SIGIR最佳论文，讨论排序中To侧观测的问题，之后分享的同学优先过下这个文章吧</p>
<p>论文题目：Search-based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S2095809919304928" target="_blank" rel="noopener noreferrer">Progress in Neural NLP: Modeling, Learning, and Reasoning<ExternalLinkIcon/></a>神经自然语言处理进展综述： 建模，学习，推理</p>
<p>本文将从建模、学习和推理三个方面综述基于神经网络的神经语言处理框架（neural NLP）的最新进展。 在建模部分，作者将描述几种基本的基于神经网络的建模范例，如单词嵌入、句子嵌入和序列到序列的建模，这些在现代NLP引擎中被广泛使用。 在学习部分，作者将介绍广泛使用的NLP模型的学习方法，包括监督学习、半监督学习和无监督学习，多任务学习，迁移学习和主动学习。 作者认为推理是神经NLP的一个新的和令人兴奋的方向，但它还没有被很好地解决。 在推理部分，作者将回顾推理机制，包括知识，现有的非神经推理方法，和新的神经推理方法。 作者在本文中强调推理的重要性，因为它对于建立可解释的和知识驱动的神经网络规划模型来处理复杂的任务是很重要的。 在本文的最后，作者将简要概述对神经语言处理的未来发展方向的思考。</p>
<h2 id="召回" tabindex="-1"><a class="header-anchor" href="#召回" aria-hidden="true">#</a> 召回</h2>
<p>[MIND][arxiv 19][Alibaba] Multi-Interest Network with Dynamic Routing for Recommendation at Tmall</p>
<p>李思臻已经在实现了</p>
<p>[SDM][CIKM 19][Alibaba] Sequential Deep Matching Model for Online Large-scale Recommender System</p>
<p>[TDM][KDD 18][Alibaba] Learning Tree-based Deep Model for Recommender Systems</p>
<h2 id="排序" tabindex="-1"><a class="header-anchor" href="#排序" aria-hidden="true">#</a> 排序</h2>
<p>[BERT4Rec][CIKM 19][Alibaba] BERT4Rec_Sequential Recommendation with Bidirectional Encoder Representations from Transformer</p>
<p>[BST][DLP-KDD 19][Alibaba] Behavior Sequence Transformer for E-commerce Recommendation in Alibaba</p>
<p><a href="https://www.infoq.cn/article/OJvS7h8JXvD4XCW*qldw" target="_blank" rel="noopener noreferrer">BST 阿里将 Transformer 用于淘宝电商推荐，效果优于 DIN 和谷歌 WDL<ExternalLinkIcon/></a></p>
<h2 id="重排序" tabindex="-1"><a class="header-anchor" href="#重排序" aria-hidden="true">#</a> 重排序</h2>
<p>[PRM][RecSys 19][Alibaba] Personalized Re-ranking for Recommendation</p>
<h2 id="embedding" tabindex="-1"><a class="header-anchor" href="#embedding" aria-hidden="true">#</a> Embedding</h2>
<p>[Airbnb Embedding][KDD 18][Airbnb] Real-time Personalization using Embeddings for Search Ranking at Airbnb</p>
<p>[Alibaba Embedding][KDD 18][Alibaba] Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba</p>
<h2 id="多任务学习" tabindex="-1"><a class="header-anchor" href="#多任务学习" aria-hidden="true">#</a> 多任务学习</h2>
<p>[RecSys 19][Alibaba] A Pareto-Efficient Algorithm for Multiple Objective Optimization in E-Commerce Recommendation</p>
<p>[ESMM][SIGIR 18][Alibaba] Entire Space Multi-Task Model_An Effective Approach for Estimating Post-Click Conversion Rate</p>
</div></template>


