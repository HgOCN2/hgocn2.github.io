<template><div><h1 id="visual-backtracking-teleoperation-a-data-collection-protocol-for-offline-image-based-reinforcement-learning" tabindex="-1"><a class="header-anchor" href="#visual-backtracking-teleoperation-a-data-collection-protocol-for-offline-image-based-reinforcement-learning" aria-hidden="true">#</a> Visual Backtracking Teleoperation: A Data Collection Protocol for Offline Image-Based Reinforcement Learning</h1>
<ul>
<li><RouterLink to="/docs/Engineering/reinforcement-learning/imatation-learning/behavior-cloning/paper/paper.html">返回上层目录</RouterLink></li>
</ul>
<p>paper: <a href="https://arxiv.org/pdf/2210.02343.pdf" target="_blank" rel="noopener noreferrer">Visual Backtracking Teleoperation: A Data Collection Protocol for Offline Image-Based Reinforcement Learning<ExternalLinkIcon/></a></p>
<p>此外，机器人团队还投入了大量的资金在更有效的数据模拟学习上，实验证明了一种简单的模仿学习方法 BC-Z 可以对训练中没有看到的新任务进行zero-shot泛化。</p>
<p>并且还引入了一个迭代模仿学习算法 GoalsEye，从游戏中学习和目标条件行为克隆相结合，用于高速高精度的乒乓球游戏。</p>
<p><a href="https://mp.weixin.qq.com/s/JRCQP2S3CbLtUaq8MkP4pQ" target="_blank" rel="noopener noreferrer">Google AI年终总结第六弹：没有波士顿动力的谷歌机器人，发展得怎么样了？<ExternalLinkIcon/></a></p>
</div></template>


