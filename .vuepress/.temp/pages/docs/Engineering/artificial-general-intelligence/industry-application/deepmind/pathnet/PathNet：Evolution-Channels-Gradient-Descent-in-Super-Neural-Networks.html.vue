<template><div><h1 id="pathnet" tabindex="-1"><a class="header-anchor" href="#pathnet" aria-hidden="true">#</a> PathNet</h1>
<ul>
<li><RouterLink to="/docs/Engineering/artificial-general-intelligence/industry-application/deepmind/deepmind.html">返回上层目录</RouterLink></li>
</ul>
<p>paper: <a href="https://arxiv.org/pdf/1701.08734.pdf" target="_blank" rel="noopener noreferrer">PathNet: Evolution Channels Gradient Descent in Super Neural Networks<ExternalLinkIcon/></a></p>
<p>===</p>
<p><a href="http://www.paopaoche.net/article/117620.html" target="_blank" rel="noopener noreferrer">DeepMind论文展示通用AI是什么样子<ExternalLinkIcon/></a></p>
<p><a href="https://zhuanlan.zhihu.com/p/25893683" target="_blank" rel="noopener noreferrer">Deepmind连续学习（序列学习）三连弹<ExternalLinkIcon/></a></p>
<p>三篇论文分别是：Progressive Neural Networks(<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1606.04671.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1606.04671.pdf<ExternalLinkIcon/></a>), PathNet: Evolution Channels Gradient Descent in Super Neural Networks(<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1701.08734.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1701.08734.pdf<ExternalLinkIcon/></a>) 和 Overcoming catastrophic forgetting in neural networks（后面我就简写EWC了）(<a href="https://link.zhihu.com/?target=http%3A//www.pnas.org/content/early/2017/03/13/1611835114.full.pdf" target="_blank" rel="noopener noreferrer">http://www.pnas.org/content/early/2017/03/13/1611835114.full.pdf<ExternalLinkIcon/></a>).</p>
</div></template>


