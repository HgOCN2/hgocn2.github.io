<template><div><h1 id="llama" tabindex="-1"><a class="header-anchor" href="#llama" aria-hidden="true">#</a> LLaMa</h1>
<ul>
<li><RouterLink to="/docs/engineering/natural-language-processing/large-language-model/industry-application/meta/meta.html">返回上层目录</RouterLink></li>
</ul>
<p>https://www.datalearner.com/ai-models/pretrained-models/LLaMA</p>
<p>开源版GPT-3来了？Meta发布LLaMa，多数任务效果超越GPT-3，已开源</p>
<p>ChatGPT的热度稍有平息，蛰伏已久的Meta就迅速放出“大招”：一次性发布四种尺寸的大语言模型LLaMA：7B、13B、33B和65B，用小杯、中杯、大杯和超大杯来解释很形象了有木有（Doge）。还声称，效果好过GPT，偏向性更低，更重要的是所有尺寸均开源，甚至13B的LLaMA在单个GPU上就能运行。消息一出，直接在网上掀起一阵热度，不到一天时间，相关推文的浏览量就已经快破百万。</p>
</div></template>


