export const data = JSON.parse("{\"key\":\"v-2d454121\",\"path\":\"/docs/engineering/reinforcement-learning/reinforcement-learning/model-based-reinforcement-learning/model-based-reinforcement-learning.html\",\"title\":\"基于模型的强化学习\",\"lang\":\"en-US\",\"frontmatter\":{},\"headers\":[{\"level\":2,\"title\":\"学习与规划\",\"slug\":\"学习与规划\",\"link\":\"#学习与规划\",\"children\":[]},{\"level\":2,\"title\":\"基于模型的强化学习\",\"slug\":\"基于模型的强化学习-1\",\"link\":\"#基于模型的强化学习-1\",\"children\":[]},{\"level\":2,\"title\":\"无模型RL和基于模型的RL\",\"slug\":\"无模型rl和基于模型的rl\",\"link\":\"#无模型rl和基于模型的rl\",\"children\":[]},{\"level\":2,\"title\":\"优势和劣势\",\"slug\":\"优势和劣势\",\"link\":\"#优势和劣势\",\"children\":[]},{\"level\":2,\"title\":\"什么是环境模型\",\"slug\":\"什么是环境模型\",\"link\":\"#什么是环境模型\",\"children\":[]},{\"level\":2,\"title\":\"模型学习\",\"slug\":\"模型学习\",\"link\":\"#模型学习\",\"children\":[]},{\"level\":2,\"title\":\"模型的例子\",\"slug\":\"模型的例子\",\"link\":\"#模型的例子\",\"children\":[]},{\"level\":2,\"title\":\"查表模型\",\"slug\":\"查表模型\",\"link\":\"#查表模型\",\"children\":[]},{\"level\":2,\"title\":\"根据模型规划\",\"slug\":\"根据模型规划\",\"link\":\"#根据模型规划\",\"children\":[]},{\"level\":2,\"title\":\"基于样本的规划\",\"slug\":\"基于样本的规划\",\"link\":\"#基于样本的规划\",\"children\":[]},{\"level\":2,\"title\":\"使用不精确的模型规划\",\"slug\":\"使用不精确的模型规划\",\"link\":\"#使用不精确的模型规划\",\"children\":[]},{\"level\":2,\"title\":\"真实的和仿真的经验\",\"slug\":\"真实的和仿真的经验\",\"link\":\"#真实的和仿真的经验\",\"children\":[]},{\"level\":2,\"title\":\"整合学习和规划\",\"slug\":\"整合学习和规划\",\"link\":\"#整合学习和规划\",\"children\":[]},{\"level\":2,\"title\":\"Dyna的结构图\",\"slug\":\"dyna的结构图\",\"link\":\"#dyna的结构图\",\"children\":[]},{\"level\":2,\"title\":\"Dyna-q的算法\",\"slug\":\"dyna-q的算法\",\"link\":\"#dyna-q的算法\",\"children\":[]},{\"level\":2,\"title\":\"一个深度强化学习的例子\",\"slug\":\"一个深度强化学习的例子\",\"link\":\"#一个深度强化学习的例子\",\"children\":[]},{\"level\":2,\"title\":\"仿真与环境模型\",\"slug\":\"仿真与环境模型\",\"link\":\"#仿真与环境模型\",\"children\":[]},{\"level\":2,\"title\":\"前向搜索（搜索树）\",\"slug\":\"前向搜索-搜索树\",\"link\":\"#前向搜索-搜索树\",\"children\":[]},{\"level\":2,\"title\":\"基于仿真的搜索详述\",\"slug\":\"基于仿真的搜索详述\",\"link\":\"#基于仿真的搜索详述\",\"children\":[]},{\"level\":2,\"title\":\"简单蒙特卡洛搜索\",\"slug\":\"简单蒙特卡洛搜索\",\"link\":\"#简单蒙特卡洛搜索\",\"children\":[]},{\"level\":2,\"title\":\"蒙特卡洛树搜索（评价）\",\"slug\":\"蒙特卡洛树搜索-评价\",\"link\":\"#蒙特卡洛树搜索-评价\",\"children\":[]},{\"level\":2,\"title\":\"蒙特卡洛树搜索（仿真）\",\"slug\":\"蒙特卡洛树搜索-仿真\",\"link\":\"#蒙特卡洛树搜索-仿真\",\"children\":[]},{\"level\":2,\"title\":\"例子：围棋\",\"slug\":\"例子-围棋\",\"link\":\"#例子-围棋\",\"children\":[]},{\"level\":2,\"title\":\"使用蒙特卡洛树搜索（MCTS）\",\"slug\":\"使用蒙特卡洛树搜索-mcts\",\"link\":\"#使用蒙特卡洛树搜索-mcts\",\"children\":[]},{\"level\":2,\"title\":\"蒙特卡洛树搜索（MCTS）\",\"slug\":\"蒙特卡洛树搜索-mcts\",\"link\":\"#蒙特卡洛树搜索-mcts\",\"children\":[]},{\"level\":2,\"title\":\"蒙特卡洛树搜索（MCTS）的优势\",\"slug\":\"蒙特卡洛树搜索-mcts-的优势\",\"link\":\"#蒙特卡洛树搜索-mcts-的优势\",\"children\":[]},{\"level\":2,\"title\":\"时间差分（TD）树搜索\",\"slug\":\"时间差分-td-树搜索\",\"link\":\"#时间差分-td-树搜索\",\"children\":[]}],\"git\":{},\"filePathRelative\":\"docs/engineering/reinforcement-learning/reinforcement-learning/model-based-reinforcement-learning/model-based-reinforcement-learning.md\"}")

if (import.meta.webpackHot) {
  import.meta.webpackHot.accept()
  if (__VUE_HMR_RUNTIME__.updatePageData) {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  }
}

if (import.meta.hot) {
  import.meta.hot.accept(({ data }) => {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  })
}
