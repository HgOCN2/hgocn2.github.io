<template><div><h1 id="self-attention机制和transformer" tabindex="-1"><a class="header-anchor" href="#self-attention机制和transformer" aria-hidden="true">#</a> Self-Attention机制和Transformer</h1>
<ul>
<li><RouterLink to="/docs/natural-language-processing/natural-language-processing.html">返回上层目录</RouterLink></li>
<li><RouterLink to="/docs/natural-language-processing/self-attention-and-transformer/attention-is-all-you-need/attention-is-all-you-need.html">Transformer: Attention Is All You Need  NIPS2017</RouterLink></li>
<li><RouterLink to="/docs/natural-language-processing/self-attention-and-transformer/transformer-tf2-demo-code-explain/transformer-tf2-demo-code-explain.html">Transformer模型tensorflow2.0官网demo代码解读</RouterLink></li>
<li><RouterLink to="/docs/natural-language-processing/self-attention-and-transformer/transformer-details/transformer-details.html">Transformer的细节问题</RouterLink></li>
</ul>
</div></template>


